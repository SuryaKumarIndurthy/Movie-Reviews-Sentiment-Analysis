# ğŸ¬ Movie Reviews Sentiment Analysis

This project performs sentiment analysis on movie reviews to classify whether a given review expresses a positive or negative opinion. The analysis involves text preprocessing, tokenization, stopword removal, vectorization, and classification using machine learning models.

## ğŸ—ƒï¸ Dataset

The dataset contains textual movie reviews labeled with sentiment:
- review: Free-text movie review
- sentiment: Binary label (0 = negative, 1 = positive)

## ğŸ§¹ Preprocessing

-Remove HTML tags
-Remove special characters
-Convert everything to lowercase
-Remove stopwords
-Stemming
- Tokenized reviews using `word_tokenize`
- Vectorized text using `TfidfVectorizer`
- Converted labels to numeric binary format

## ğŸ§  Model Training
The project uses three variants of the Naive Bayes algorithm to classify the sentiment of movie reviews:
Models Trained:
-GaussianNB() â€“ for continuous features (not ideal for sparse text data, but tested)
-MultinomialNB() â€“ best suited for text classification with word counts or TF-IDF
-BernoulliNB() â€“ works well with binary/boolean feature vectors (e.g., word presence)


## ğŸ“ˆ Results

ğŸ”µ Bernoulli Naive Bayes (BNB) achieved the highest accuracy, making it the best-performing model for this binary sentiment classification task. Its ability to handle binary features (word presence/absence) aligns well with TF-IDFâ€™s sparsity.
ğŸŸ¡ Multinomial Naive Bayes (MNB) closely followed, performing strongly with frequency-based inputs. This model is commonly used in NLP and remains a reliable option.
ğŸ”´ Gaussian Naive Bayes (GNB) underperformed due to its assumption of normally distributed continuous features, which does not match the sparse, high-dimensional structure of TF-IDF vectors.
â€¢	For TF-IDF-based sentiment classification, BernoulliNB slightly outperforms MultinomialNB.
â€¢	GaussianNB is not recommended for text data unless feature engineering transforms the data to continuous distributions.
